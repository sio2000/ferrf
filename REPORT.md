# Full-Text Search Engine Implementation
## PostgreSQL Full Text Search on PubMed Central Articles

**Academic Report**

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Dataset Description](#2-dataset-description)
3. [Database Schema Design](#3-database-schema-design)
4. [Data Loading Process](#4-data-loading-process)
5. [Full Text Search Theory](#5-full-text-search-theory)
6. [Indexing Strategy](#6-indexing-strategy)
7. [Query Analysis & Results](#7-query-analysis--results)
8. [Ranking & Term Statistics](#8-ranking--term-statistics)
9. [Web Application Architecture](#9-web-application-architecture)
10. [Conclusions](#10-conclusions)

---

## 1. Introduction

This report presents a complete implementation of a full-text search engine built on PostgreSQL's native Full Text Search (FTS) capabilities. The system processes approximately 100,000 scientific articles from PubMed Central, providing efficient search functionality over article titles and abstracts.

The primary objectives of this project are:
- To demonstrate proficiency in database design and optimization
- To implement and evaluate PostgreSQL's full-text search features
- To create a production-ready search system with proper indexing
- To analyze search performance and term statistics

The implementation follows academic and production-level standards, ensuring correctness, efficiency, and reproducibility.

---

## 2. Dataset Description

### 2.1 Data Source

The dataset consists of scientific articles from PubMed Central in JSON Lines format. Each line contains a single JSON object representing one article.

### 2.2 Data Structure

Each article contains the following fields:
- **title**: The article title (TEXT)
- **abstract**: The article abstract (TEXT)
- **authors**: Array of author objects with surname and given_names
- **biblio**: Bibliographic information (journal, year, volume, etc.)
- **pmid**: PubMed ID

### 2.3 Dataset Statistics

- **Total Articles**: ~100,000 documents
- **Format**: JSON Lines (one JSON object per line)
- **Encoding**: UTF-8
- **Size**: Approximately 50MB (compressed)

### 2.4 Data Quality Considerations

The loading process handles:
- Missing titles (NULL or empty strings)
- Missing abstracts (NULL or empty strings)
- Special characters and Unicode encoding
- Large text fields (abstracts can be several thousand characters)

---

## 3. Database Schema Design

### 3.1 Initial Schema (Part A)

The initial `docs` table schema is designed for simplicity and efficiency:

```sql
CREATE TABLE docs (
    id INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    title TEXT,
    abstract TEXT
);
```

**Design Decisions:**
- **ID**: Auto-generated identity column for efficient primary key
- **TEXT type**: PostgreSQL's TEXT type is optimal for variable-length strings without length restrictions
- **No NOT NULL constraints**: Some articles may have missing titles or abstracts

### 3.2 Extended Schema (Part B)

For full-text search, we extend the schema with TSVECTOR columns:

```sql
ALTER TABLE docs 
ADD COLUMN title_tsv TSVECTOR,
ADD COLUMN abstract_tsv TSVECTOR;
```

**TSVECTOR Explanation:**
- TSVECTOR is PostgreSQL's data type for full-text search
- Contains preprocessed, normalized tokens from the source text
- Tokens are stemmed and stop words are removed
- Enables efficient search operations using the `@@` operator

### 3.3 Schema Optimization

- **Separate TSVECTOR columns**: Allows searching title and abstract independently
- **Composite search capability**: Can combine both columns using `||` operator
- **Index-friendly**: TSVECTOR columns are indexed with GIN indexes for performance

---

## 4. Data Loading Process

### 4.1 Loading Strategy

The data loading process follows these steps:

1. **Create temporary table** for raw JSON data
2. **Load JSON Lines** into temporary table
3. **Extract and transform** title and abstract fields
4. **Insert into docs table** with NULL handling
5. **Verify data integrity**

### 4.2 Implementation Approach

We use a Python script (`load_data.py`) for data loading because:
- JSON Lines format is easier to process programmatically
- Better error handling for malformed JSON
- Batch insertion for performance
- Cross-platform compatibility

### 4.3 SQL-Based Loading (Alternative)

For environments where file access is available, we provide SQL-based loading:

```sql
-- Create temporary table
CREATE TEMP TABLE temp_json_data (
    json_data JSONB
);

-- Load JSON Lines (requires file system access)
COPY temp_json_data(json_data) 
FROM PROGRAM 'cat /path/to/data.txt' 
(FORMAT text);

-- Extract and insert
INSERT INTO docs (title, abstract)
SELECT 
    COALESCE(json_data->>'title', '') AS title,
    COALESCE(json_data->>'abstract', '') AS abstract
FROM temp_json_data
WHERE json_data->>'title' IS NOT NULL 
   OR json_data->>'abstract' IS NOT NULL;
```

### 4.4 Data Quality Handling

The loading process handles:
- **NULL values**: Uses `COALESCE()` to convert NULL to empty string
- **Missing fields**: Filters out documents with both title and abstract missing
- **Encoding**: Proper UTF-8 handling for international characters
- **Large files**: Batch processing to manage memory efficiently

### 4.5 Loading Performance

- **Batch size**: 1,000 records per batch
- **Transaction management**: Commits after each batch
- **Error recovery**: Continues processing on individual record errors
- **Verification**: Post-load statistics to confirm data integrity

---

## 5. Full Text Search Theory

### 5.1 PostgreSQL Full Text Search Overview

PostgreSQL's Full Text Search (FTS) is a powerful system for searching text documents. It provides:

- **Tokenization**: Splits text into words (tokens)
- **Normalization**: Converts to lowercase, removes accents
- **Stemming**: Reduces words to root forms (e.g., "running" → "run")
- **Stop word removal**: Filters common words (the, a, an, etc.)
- **Ranking**: Scores documents by relevance

### 5.2 Key Components

#### 5.2.1 TSVECTOR

TSVECTOR is a sorted list of distinct lexemes (normalized words):

```sql
SELECT to_tsvector('english', 'The quick brown fox');
-- Result: 'brown':3 'fox':4 'quick':2
```

- Numbers indicate word positions
- Stop words ("the") are removed
- Words are normalized to lowercase

#### 5.2.2 TSQUERY

TSQUERY represents a search query:

```sql
SELECT to_tsquery('english', 'fox & brown');
-- Result: 'fox' & 'brown'
```

**Operators:**
- `&` (AND): Both terms must appear
- `|` (OR): Either term can appear
- `!` (NOT): Term must not appear
- `()`: Grouping for complex queries

#### 5.2.3 Match Operator (@@)

The `@@` operator checks if a TSVECTOR matches a TSQUERY:

```sql
SELECT * FROM docs 
WHERE title_tsv @@ to_tsquery('english', 'cancer');
```

### 5.3 Text Search Functions

#### 5.3.1 to_tsvector()

Converts text to TSVECTOR:

```sql
to_tsvector(config, text) → TSVECTOR
```

- **config**: Language configuration (e.g., 'english')
- **text**: Source text to process

#### 5.3.2 to_tsquery() vs plainto_tsquery()

- **to_tsquery()**: Expects properly formatted query with operators
  ```sql
  to_tsquery('english', 'rat | liver')  -- OR operator
  to_tsquery('english', 'rat & liver')   -- AND operator
  ```

- **plainto_tsquery()**: User-friendly, automatically handles operators
  ```sql
  plainto_tsquery('english', 'rat liver')  -- Automatically becomes AND
  ```

### 5.4 Ranking Functions

#### 5.4.1 ts_rank()

Standard ranking based on term frequency:

```sql
ts_rank(tsvector, tsquery) → REAL
```

#### 5.4.2 ts_rank_cd()

Cover density ranking (used in this project):

```sql
ts_rank_cd(tsvector, tsquery) → REAL
```

**Advantages:**
- Considers proximity of matching terms
- Better relevance scoring
- More suitable for multi-term queries

---

## 6. Indexing Strategy

### 6.1 GIN Indexes

We use **GIN (Generalized Inverted Index)** indexes for TSVECTOR columns:

```sql
CREATE INDEX idx_docs_title_tsv ON docs USING GIN (title_tsv);
CREATE INDEX idx_docs_abstract_tsv ON docs USING GIN (abstract_tsv);
CREATE INDEX idx_docs_combined_tsv ON docs 
USING GIN ((title_tsv || abstract_tsv));
```

### 6.2 Why GIN?

**GIN indexes are optimal for:**
- Full-text search operations
- Array operations
- JSONB queries
- Containment checks

**Characteristics:**
- **Fast lookups**: O(log n) search time
- **Space efficient**: Compressed storage
- **Update performance**: Slightly slower than B-tree, but acceptable for read-heavy workloads

### 6.3 Index Design

We create three indexes:

1. **title_tsv index**: For title-only searches
2. **abstract_tsv index**: For abstract-only searches
3. **combined index**: For searches across both fields

### 6.4 Automatic TSVECTOR Updates

We use triggers to automatically update TSVECTOR columns:

```sql
CREATE TRIGGER docs_tsvector_update
    BEFORE INSERT OR UPDATE ON docs
    FOR EACH ROW
    EXECUTE FUNCTION update_docs_tsvector();
```

**Benefits:**
- Ensures TSVECTOR columns are always current
- No manual maintenance required
- Consistent data integrity

### 6.5 Index Maintenance

- **ANALYZE**: Updates query planner statistics
- **VACUUM**: Reclaims storage and updates visibility map
- **REINDEX**: Rebuilds indexes if needed

---

## 7. Query Analysis & Results

### 7.1 Query Categories

We implement queries in two categories:
- **OR queries**: 'rat' OR 'liver'
- **AND queries**: 'rat' AND 'liver'

Each category includes four variations:
- A: Title only
- B: Abstract only
- C: Title OR Abstract
- D: Title AND Abstract

### 7.2 Query A: Title Contains 'rat' OR 'liver'

```sql
SELECT COUNT(*) AS count_title_rat_or_liver
FROM docs
WHERE title_tsv @@ to_tsquery('english', 'rat | liver');
```

**Explanation:**
- Uses `|` operator for OR logic
- Searches only in `title_tsv` column
- Uses GIN index for efficient execution

### 7.3 Query B: Abstract Contains 'rat' OR 'liver'

```sql
SELECT COUNT(*) AS count_abstract_rat_or_liver
FROM docs
WHERE abstract_tsv @@ to_tsquery('english', 'rat | liver');
```

**Explanation:**
- Similar to Query A, but searches `abstract_tsv`
- Abstracts are typically longer, so may return more results

### 7.4 Query C: Title OR Abstract Contains 'rat' OR 'liver'

```sql
SELECT COUNT(*) AS count_title_or_abstract_rat_or_liver
FROM docs
WHERE (title_tsv || abstract_tsv) @@ to_tsquery('english', 'rat | liver');
```

**Explanation:**
- Combines both TSVECTOR columns using `||`
- Uses combined GIN index for performance
- Returns documents where term appears in either field

### 7.5 Query D: Title AND Abstract Both Contain 'rat' OR 'liver'

```sql
SELECT COUNT(*) AS count_title_and_abstract_rat_or_liver
FROM docs
WHERE title_tsv @@ to_tsquery('english', 'rat | liver')
  AND abstract_tsv @@ to_tsquery('english', 'rat | liver');
```

**Explanation:**
- Requires match in BOTH title and abstract
- More restrictive than Query C
- Uses two separate index lookups

### 7.6 Query E: AND Queries

Queries E-A through E-D repeat the same patterns but with AND logic:

```sql
-- Example: Title contains 'rat' AND 'liver'
SELECT COUNT(*) AS count_title_rat_and_liver
FROM docs
WHERE title_tsv @@ to_tsquery('english', 'rat & liver');
```

**Key Difference:**
- Uses `&` operator instead of `|`
- More restrictive (both terms required)
- Typically returns fewer results

### 7.7 Query F: Ranked Search

```sql
SELECT 
    id,
    title,
    LEFT(abstract, 200) AS abstract_preview,
    ts_rank_cd(abstract_tsv, to_tsquery('english', 'cancer & liver')) AS rank
FROM docs
WHERE abstract_tsv @@ to_tsquery('english', 'cancer & liver')
ORDER BY rank DESC;
```

**Features:**
- Uses `ts_rank_cd()` for relevance scoring
- Orders by descending rank (most relevant first)
- Returns full document details, not just count
- Truncates abstract for display

**Ranking Explanation:**
- Higher rank = more relevant
- Considers term frequency and proximity
- Documents with both terms close together rank higher

### 7.8 Expected Results Analysis

**OR Queries (rat | liver):**
- Typically return more results than AND queries
- Useful for broad searches
- May include less relevant documents

**AND Queries (rat & liver):**
- More precise results
- Higher relevance
- Fewer false positives

**Field Comparison:**
- Abstract searches usually return more results (longer text)
- Title searches are more specific
- Combined searches maximize recall

---

## 8. Ranking & Term Statistics

### 8.1 Document Frequency (DF)

**Definition:** Number of documents containing a term.

**Query G Implementation:**

```sql
SELECT 
    word AS term,
    ndoc AS document_frequency
FROM ts_stat('SELECT title_tsv || abstract_tsv FROM docs 
              WHERE title_tsv IS NOT NULL OR abstract_tsv IS NOT NULL')
ORDER BY ndoc DESC
LIMIT 10;
```

**Interpretation:**
- High DF = common term (e.g., "the", "study", "results")
- Low DF = rare term (e.g., specific medical conditions)
- Useful for understanding corpus characteristics

### 8.2 Collection Frequency (CF)

**Definition:** Total number of occurrences of a term across all documents.

**Query H Implementation:**

```sql
SELECT 
    word AS term,
    nentry AS collection_frequency
FROM ts_stat('SELECT title_tsv || abstract_tsv FROM docs 
              WHERE title_tsv IS NOT NULL OR abstract_tsv IS NOT NULL')
ORDER BY nentry DESC
LIMIT 10;
```

**Interpretation:**
- CF ≥ DF (term can appear multiple times per document)
- High CF = frequently used term
- Ratio CF/DF indicates average term frequency per document

### 8.3 Term Statistics Use Cases

1. **Stop word identification**: Terms with very high DF/CF
2. **Domain-specific vocabulary**: Medical/scientific terms
3. **Index optimization**: Focus indexing on important terms
4. **Query expansion**: Suggest related terms

---

## 9. Web Application Architecture

### 9.1 Technology Stack

- **Backend**: Flask (Python web framework)
- **Database**: PostgreSQL with FTS
- **Frontend**: HTML, CSS, JavaScript (vanilla)
- **Connection**: psycopg2 (PostgreSQL adapter)

### 9.2 Architecture Overview

```
┌─────────────┐
│   Browser   │
└──────┬──────┘
       │ HTTP
       ▼
┌─────────────┐
│  Flask App  │
│  (app.py)   │
└──────┬──────┘
       │ SQL
       ▼
┌─────────────┐
│ PostgreSQL  │
│   (FTS)     │
└─────────────┘
```

### 9.3 Key Components

#### 9.3.1 Search Endpoint

```python
@app.route('/search', methods=['GET', 'POST'])
def search():
    query = request.args.get('q', '').strip()
    
    search_query = """
        SELECT 
            id, title, LEFT(abstract, 500) AS abstract_preview,
            ts_rank_cd((title_tsv || abstract_tsv), 
                       plainto_tsquery('english', %s)) AS rank
        FROM docs
        WHERE (title_tsv || abstract_tsv) @@ plainto_tsquery('english', %s)
        ORDER BY rank DESC
        LIMIT 50
    """
```

**Features:**
- Uses `plainto_tsquery()` for user-friendly queries
- Ranks results with `ts_rank_cd()`
- Limits to 50 results for performance
- Returns JSON for AJAX requests

#### 9.3.2 Statistics Endpoint

```python
@app.route('/stats', methods=['GET'])
def stats():
    # Returns total documents, documents with title/abstract
```

Provides real-time database statistics.

### 9.4 Frontend Design

**Features:**
- Modern, responsive UI
- Real-time search (no page reload)
- Ranked results display
- Statistics dashboard
- Error handling and loading states

### 9.5 Security Considerations

- **SQL Injection Prevention**: Parameterized queries
- **XSS Prevention**: HTML escaping in templates
- **Input Validation**: Query sanitization
- **Error Handling**: Graceful error messages

### 9.6 Performance Optimizations

- **Connection Pooling**: Reuse database connections
- **Query Limiting**: Max 50 results per query
- **Index Usage**: All queries use GIN indexes
- **Caching**: Consider Redis for frequent queries (future enhancement)

---

## 10. Conclusions

### 10.1 Project Summary

This project successfully implements a full-text search engine using PostgreSQL's native FTS capabilities. The system processes ~100,000 scientific articles and provides:

- Efficient data loading from JSON Lines format
- Optimized full-text search with GIN indexes
- Comprehensive query implementation (OR, AND, ranking)
- Term statistics analysis (DF, CF)
- Production-ready web application

### 10.2 Key Achievements

1. **Complete Implementation**: All required components implemented
2. **Performance**: GIN indexes ensure fast query execution
3. **Scalability**: Architecture supports large datasets
4. **Usability**: Web interface provides intuitive search experience
5. **Documentation**: Comprehensive code and report documentation

### 10.3 Technical Insights

**PostgreSQL FTS Strengths:**
- Native integration with database
- Efficient indexing (GIN)
- Flexible query syntax
- Good ranking algorithms
- Language-specific configurations

**Design Decisions:**
- Separate TSVECTOR columns for flexibility
- Automatic updates via triggers
- Combined indexes for multi-field search
- Cover density ranking for better relevance

### 10.4 Future Enhancements

1. **Query Expansion**: Suggest related terms
2. **Faceted Search**: Filter by journal, year, etc.
3. **Advanced Ranking**: Custom ranking functions
4. **Caching Layer**: Redis for frequent queries
5. **Analytics**: Search query analytics
6. **Multi-language Support**: Additional language configurations

### 10.5 Lessons Learned

- **Indexing is Critical**: GIN indexes dramatically improve performance
- **Ranking Matters**: `ts_rank_cd()` provides better relevance than `ts_rank()`
- **User Experience**: `plainto_tsquery()` is more user-friendly than `to_tsquery()`
- **Data Quality**: Proper NULL handling is essential
- **Scalability**: Batch processing is necessary for large datasets

### 10.6 Academic Contribution

This implementation demonstrates:
- Proficiency in database design and optimization
- Understanding of information retrieval principles
- Ability to build production-ready systems
- Academic writing and documentation skills

---

## References

1. PostgreSQL Documentation: Full Text Search
   https://www.postgresql.org/docs/current/textsearch.html

2. PostgreSQL Documentation: GIN Indexes
   https://www.postgresql.org/docs/current/gin.html

3. PubMed Central: Open Access Articles
   https://www.ncbi.nlm.nih.gov/pmc/

4. Flask Documentation
   https://flask.palletsprojects.com/

---

## Appendix A: Complete SQL Scripts

See files:
- `01_schema.sql`
- `02_load_data.sql`
- `03_fts_setup.sql`
- `04_queries.sql`

## Appendix B: Python Code

See files:
- `load_data.py`
- `app.py`

## Appendix C: Web Application

See directory:
- `templates/index.html`

---

**Report Generated**: December 2024  
**Author**: Database & Information Retrieval Engineer  
**Institution**: University Project  
**Version**: 1.0

